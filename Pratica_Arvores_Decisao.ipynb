{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lopes-andre/brains/blob/main/Pratica_Arvores_Decisao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc96b35a",
      "metadata": {
        "id": "fc96b35a"
      },
      "source": [
        "<h1><center>BRAINS - Brazilian AI Networks üß†</center></h1>\n",
        "\n",
        "<center><i>BRAINS - Brazilian AI Networks - √© uma comunidade de estudantes brasileiros que tem como objetivo trazer conte√∫do de qualidade sobre AI, Machine Learning e Dados para o Brasil, em Portugu√™s.</i> üáßüá∑</center>\n",
        "\n",
        "<h1><center>Pr√°tica: √Årvores de Decis√£o</center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "675cf892",
      "metadata": {
        "id": "675cf892"
      },
      "source": [
        "## Introdu√ß√£o\n",
        "\n",
        "Iremos agora, neste notebook, abordar de forma pr√°tica a constru√ß√£o de modelos de **√Årvores de Decis√£o** (ou *Decision Trees*), para um problema de Classifica√ß√£o Bin√°ria.\n",
        "\n",
        "J√° conversamos sobre a teoria dos Modelos de Classifica√ß√£o e tamb√©m das √Årvores de Decis√£o nos seguintes posts.\n",
        "\n",
        "- [√Årvores de Decis√£o: Algoritmos Baseados em √Årvores](https://brains.dev/2023/arvores-de-decisao-algoritmos-baseados-em-arvores/)\n",
        "\n",
        "\n",
        "- [Medidas de Performance: Modelos de Classifica√ß√£o](https://brains.dev/2023/medidas-de-performance-modelos-de-classificacao/)\n",
        "\n",
        "\n",
        "Se voc√™ ainda n√£o leu estes dois posts, a leitura √© recomendada. Mas se voc√™ j√° leu, ou domina os temas, bora programar!\n",
        "\n",
        "## Objetivos\n",
        "\n",
        "Para minimizar as perdas de um banco fict√≠cio, precisamos desenvolver um processo de tomada de decis√£o sobre para quem o banco deve aprovar empr√©stimos e para quem n√£o. Os perfis demogr√°fico e socioecon√¥mico do cliente s√£o considerados pelos fict√≠cios gerentes de empr√©stimos antes da tomada de decis√£o sobre o pedido de empr√©stimo.\n",
        "\n",
        "Com base na base de dados de clientes que pegaram empr√©stimos no banco fict√≠cio, temos classificados os clientes inadimplentes e os clientes e quitaram as suas d√≠vidas.\n",
        "\n",
        "Nosso objetivo √© construir um Modelo de Machine Learning que ir√° prever se um cliente que aplica para um empr√©stimo pode ser ou n√£o um cliente inadimplente.\n",
        "\n",
        "## Descri√ß√£o dos Dados\n",
        "\n",
        "Nossa base de dados √© um dataset p√∫blico, disponibilizado pelo *Center for Machine Learning and Intelligent Systems*  da Universidade da Calif√≥rnia, UCI. \n",
        "\n",
        "Link do dataset: https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\n",
        "\n",
        "> ***Nota:*** *Trata-se de um dataset de um banco da Alemanha, doado para uso p√∫blico em 1994. Toda a base de dados original est√° em Ingl√™s. Foi feita uma tradu√ß√£o livre e pequenas manipula√ß√µes de dados para fins did√°ticos.*\n",
        "\n",
        "A base de dados √© composta pelas seguintes colunas.\n",
        "\n",
        "- **saldo_corrente:** saldo na conta corrente (categ√≥rica).\n",
        "\n",
        "- **duracao_emp_meses:** dura√ß√£o do empr√©stimo, em meses (num√©rica).\n",
        "\n",
        "- **historico_credito:** hist√≥rico de cr√©dito (categ√≥rica).\n",
        "\n",
        "- **motivo:** motivo para pedido de empr√©stimo (categ√≥rica).\n",
        "\n",
        "- **quantia:** valor do empr√©stimo pedido (num√©rica).\n",
        "\n",
        "- **saldo_poupanca:** saldo na conta poupan√ßa (categ√≥rica).\n",
        "\n",
        "- **tempo_empregado:** tempo no emprego atual (categ√≥rica).\n",
        "\n",
        "- **porcentagem_renda:** porcentagem da renda comprometida pela parcela do empr√©stimo (num√©rica).\n",
        "\n",
        "- **anos_residencia:** tempo de moradia na resid√™ncia atual, em anos (num√©rica).\n",
        "\n",
        "- **idade:** idade do cliente, em anos (num√©rica).\n",
        "\n",
        "- **outro_credito:** se o cliente possui empr√©stimos em outros estabelecimentos (categ√≥rica).\n",
        "\n",
        "- **residencia:** se mora em resid√™ncia pr√≥pria ou alugada (categ√≥rica).\n",
        "\n",
        "- **qtd_emprestimos_existentes:** quantidade de empr√©stimos existentes neste banco (num√©rica).\n",
        "\n",
        "- **emprego:** categoria de emprego (categ√≥rica).\n",
        "\n",
        "- **dependentes:** quantidade de dependentes (num√©rica).\n",
        "\n",
        "- **telefone:** se o cliente possui telefone, informa√ß√£o relevante na √©poca (categ√≥rica).\n",
        "\n",
        "- **inadimplente:** classifica√ß√£o se o cliente foi inadimplente ou n√£o, nossa **vari√°vel alvo**.\n",
        "\n",
        "<br><br>\n",
        "## Importando as Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install sklearn"
      ],
      "metadata": {
        "id": "GaXXGcAK7uHO"
      },
      "id": "GaXXGcAK7uHO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d0de157",
      "metadata": {
        "id": "8d0de157"
      },
      "outputs": [],
      "source": [
        "# Manipula√ß√£o de dados\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualiza√ß√£o de dados\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Divis√£o dos dados\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Algoritmos de Machine Learning\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# M√©tricas de performance\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import (f1_score,\n",
        "                            accuracy_score,\n",
        "                            recall_score,\n",
        "                            precision_score,\n",
        "                            confusion_matrix,\n",
        "                            plot_confusion_matrix,\n",
        "                            roc_auc_score)\n",
        "\n",
        "# Ajustes de Hiperparametros\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Optional para Annotations das fun√ß√µes\n",
        "from typing import Optional\n",
        "\n",
        "# Ignorar alertas\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26a7d57",
      "metadata": {
        "id": "d26a7d57"
      },
      "source": [
        "N√≥s iremos construir nosso modelo de √Årvores de Decis√£o usando a biblioteca [`scikit-learn`](https://scikit-learn.org/stable/).\n",
        "\n",
        "<br>\n",
        "\n",
        "## Carregando e Explorando os Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cc67759",
      "metadata": {
        "id": "3cc67759"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "# Local do dataset online\n",
        "url_dataset = 'https://raw.githubusercontent.com/lopes-andre/datasets/main/credito.csv'\n",
        "\n",
        "# Carrega os dados em um DataFrame\n",
        "data = pd.read_csv(url_dataset)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c9e071d",
      "metadata": {
        "id": "7c9e071d"
      },
      "outputs": [],
      "source": [
        "# Verifica o shape dos dados\n",
        "print(f'Shape dos dados: {data.shape}\\n')\n",
        "\n",
        "print(f'Esta base de dados tem {data.shape[0]} linhas e {data.shape[1]} colunas.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d4a6f9",
      "metadata": {
        "id": "56d4a6f9"
      },
      "outputs": [],
      "source": [
        "# Resumo Estat√≠stico dos dados\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea517136",
      "metadata": {
        "id": "ea517136"
      },
      "source": [
        "#### Observa√ß√µes\n",
        "\n",
        "- N√≥s podemos com apenas uma linha de c√≥digo ver todo o resumo estat√≠stico dos dados.\n",
        "\n",
        "\n",
        "- Este m√©todo nos retorna as seguintes informa√ß√µes:\n",
        "\n",
        "  - Contagem de entradas de cada coluna.\n",
        "\n",
        "  - M√©dia.\n",
        "\n",
        "  - Desvio Padr√£o.\n",
        "\n",
        "  - Valores m√≠nimo e m√°ximo de cada coluna.\n",
        "\n",
        "  - Primeiro quartil, Mediana e terceiro quartil.\n",
        "  \n",
        "\n",
        "- Todas as entradas num√©ricas s√£o retornadas.\n",
        "\n",
        "\n",
        "Para analisar os dados das colunas Categ√≥ricas, podemos usar um outro trecho de c√≥digo. A c√©lula abaixo ir√° isolar as colunas do tipo `object` e analisar as entradas de cada uma destas colunas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "951c947f",
      "metadata": {
        "id": "951c947f"
      },
      "outputs": [],
      "source": [
        "# Lista de vari√°veis categ√≥ricas\n",
        "colunas_cat = data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Loop para imprimir a contagem de valores √∫nicos em cada coluna categ√≥rica\n",
        "for coluna in colunas_cat:\n",
        "    print(f'### Coluna <{coluna}> ###')\n",
        "    print(data[coluna].value_counts())\n",
        "    print('-' * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60e3ac46",
      "metadata": {
        "id": "60e3ac46"
      },
      "outputs": [],
      "source": [
        "# Verifica os tipos das colunas e quantidade de entradas\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "380bf733",
      "metadata": {
        "id": "380bf733"
      },
      "outputs": [],
      "source": [
        "# Verificando dados nulos\n",
        "print('Colunas com dados nulos:')\n",
        "display(data.isnull().sum()[data.isnull().sum() > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9165e18",
      "metadata": {
        "id": "f9165e18"
      },
      "source": [
        "### Observa√ß√µes sobre o Resumo dos Dados\n",
        "\n",
        "- Os valores monet√°rios est√£o em Deutsche Mark (DM), moeda da Alemanha na √©poca, anterior ao Euro.\n",
        "\n",
        "\n",
        "- As colunas `duracao_emp_meses` , `porcentagem_renda` e `anos_residencia` t√™m valores nulos/faltantes. Valores nulos podem causar resultados inesperados em modelos preditivos, portanto iremos tratar esses valores com Engenharia de Atributos.\n",
        "\n",
        "\n",
        "- A m√©dia de idade √© aproximadamente 35 anos e a mediana √© 33 anos.\n",
        "\n",
        "\n",
        "- A m√©dia de valor dos empr√©stimos est√° em torno de 3271 DM (Deutsche Mark), mas h√° um grande range de 250 DM a 18434 DM. Poder√≠amos analisar melhor estes dados na An√°lise Explorat√≥ria de Dados.\n",
        "\n",
        "\n",
        "- A m√©dia de parcelas dos empr√©stimos est√° em torno de 21 meses e a mediana em 18 meses.\n",
        "\n",
        "\n",
        "- Temos poucos clientes desempregados na base de dados.\n",
        "\n",
        "\n",
        "- H√° uma classe na coluna `motivo` que parece ter sofrido erro de digita√ß√£o. Iremos tratar isso com a Engenharia de Atributos.\n",
        "\n",
        "\n",
        "- A nossa vari√°vel alvo, `inadimplente`, est√° desbalanceada. Apenas 30% das observa√ß√µes est√£o na Classe 1 (inadimplente) e 70% na Classe 0 (n√£o inadimplente).\n",
        "\n",
        "\n",
        "A An√°lise Explorat√≥ria dos Dados para este Dataset pode ficar bem extensa, portanto deixaremos para abordar ela completa em outro post, ok?\n",
        "\n",
        "Vamos direto para a **Engenharia de Atributos** (ou ***Feature Engineering***)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f0ea029",
      "metadata": {
        "id": "4f0ea029"
      },
      "source": [
        "## Engenharia de Atributos\n",
        "\n",
        "Durante a fase de Engenharia de Atributos iremos preparar o dataset para a modelagem preditiva. Poder√≠amos ter realizado algumas dessas transforma√ß√µes antes da An√°lise Explorat√≥ria de Dados, mas para fins did√°ticos centralizamos aqui nesta sess√£o todos os passos.\n",
        "\n",
        "### Corrigindo Erros nos Atributos\n",
        "\n",
        "Como mencionado acima, h√° um erro de digita√ß√£o em uma das categorias do atributo `motivo` . Vamos analisar este ponto e corrigir conforme necess√°rio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c092c622",
      "metadata": {
        "id": "c092c622"
      },
      "outputs": [],
      "source": [
        "# Exibe as categorias da vari√°vel motivo\n",
        "data['motivo'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab2f18f7",
      "metadata": {
        "id": "ab2f18f7"
      },
      "outputs": [],
      "source": [
        "# Corrige o erro de digita√ß√£o\n",
        "corrige_carro = {'carr0': 'carro'}\n",
        "data.replace(corrige_carro, inplace=True)\n",
        "\n",
        "# Verifica as categorias novamente\n",
        "data['motivo'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d302261",
      "metadata": {
        "id": "7d302261"
      },
      "source": [
        "Note que a entrada `\"carr0\"`, que era aparentemente um erro de digita√ß√£o, j√° n√£o existe mais. \n",
        "\n",
        "O problema foi corrigido. N√≥s substitu√≠mos as entradas `\"carr0\"` por `\"carro\"`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe4e1d6e",
      "metadata": {
        "id": "fe4e1d6e"
      },
      "source": [
        "## Transformando Vari√°veis Categ√≥ricas em Num√©ricas para Modelagem\n",
        "\n",
        "A maioria dos algoritmos de Machine Learning n√£o lidam bem com vari√°veis categ√≥ricas em forma de texto. Para isto, precisamos converter as vari√°veis categ√≥ricas em num√©ricas, para facilitar os c√°lculos matem√°ticos dos algoritmos.\n",
        "\n",
        "As vari√°veis ordinais, que apresentam uma ordem l√≥gica, podem ser convertidas usando a mesma fun√ß√£o acima, por√©m com uma l√≥gica diferente: atribuindo valores num√©ricos sequenciais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d13ec6",
      "metadata": {
        "id": "31d13ec6"
      },
      "outputs": [],
      "source": [
        "# Convertendo vari√°veis Categ√≥ricas Ordinais\n",
        "conversao_variaveis = {\n",
        "    'saldo_corrente': {\n",
        "        'desconhecido': -1,\n",
        "        '< 0 DM': 1,\n",
        "        '1 - 200 DM': 2,\n",
        "        '> 200 DM': 3,\n",
        "    },\n",
        "    'historico_credito': {\n",
        "        'critico': 1,\n",
        "        'ruim': 2,\n",
        "        'bom': 3,\n",
        "        'muito bom': 4,\n",
        "        'perfeito': 5\n",
        "    },\n",
        "    'saldo_poupanca': {\n",
        "        'desconhecido': -1,\n",
        "        '< 100 DM': 1,\n",
        "        '100 - 500 DM': 2,\n",
        "        '500 - 1000 DM': 3,\n",
        "        '> 1000 DM': 4,\n",
        "    },\n",
        "    'tempo_empregado': {\n",
        "        'desempregado': 1,\n",
        "        '< 1 ano': 2,\n",
        "        '1 - 4 anos': 3,\n",
        "        '4 - 7 anos': 4,\n",
        "        '> 7 anos': 5,\n",
        "    },\n",
        "    'telefone': {\n",
        "        'nao': 1,\n",
        "        'sim': 2,\n",
        "    }\n",
        "}\n",
        "\n",
        "data.replace(conversao_variaveis, inplace=True)\n",
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb039e17",
      "metadata": {
        "id": "eb039e17"
      },
      "source": [
        "### OneHotEncoding para Vari√°veis N√£o Ordinais\n",
        "\n",
        "Para vari√°veis categ√≥ricas podemos aplicar a t√©cnica de **OneHotEncoding**. Nesta t√©cnica, cada categoria se transforma em uma coluna de valores bin√°rios (0 ou 1). Por exemplo, o atributo `motivo` que possui 5 categorias, vai se transformar em 4 colunas distintas.\n",
        "\n",
        "#### Exemplo\n",
        "\n",
        "O atributo `motivo` possui 5 categorias:\n",
        "\n",
        "1. moveis/eletrodomesticos\n",
        "2. carro\n",
        "3. negocios\n",
        "4. educacao\n",
        "5. renovacao\n",
        "\n",
        "Ao aplicar a t√©cnica de OneHotEncoding, o DataFrame ficaria da seguinte forma.\n",
        "\n",
        "| motivo | motivo_carro | motivo_negocios | motivo_educacao | motivo_renovacao |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| carro | 1 | 0 | 0 | 0 |\n",
        "| negocios | 0 | 1 | 0 | 0 |\n",
        "| educacao | 0 | 0 | 1 | 0 |\n",
        "| renovacao | 0 | 0 | 0 | 1 |\n",
        "| moveis/eletrodomesticos | 0 | 0 | 0 | 0 |\n",
        "\n",
        "Para evitar a Multicolinearidade, n√≥s configuramos a fun√ß√£o para dropar a primeira coluna, pois ela n√£o √© necess√°ria. Caso a observa√ß√£o n√£o se encaixe em nenhuma das 4 categorias acima, ela obviamente vai se encaixar na quinta, que no nosso caso √© a `moveis/eletrodomesticos` . 0 em todas as colunas significa que est√° nesta categoria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5795ada",
      "metadata": {
        "id": "a5795ada"
      },
      "outputs": [],
      "source": [
        "# Gera a lista de vari√°veis categ√≥ricas\n",
        "cols_cat = data.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Removendo 'inadimplente' pois √© nossa vari√°vel Alvo\n",
        "cols_cat.remove('inadimplente')\n",
        "\n",
        "cols_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdee841",
      "metadata": {
        "id": "0bdee841"
      },
      "outputs": [],
      "source": [
        "# Implementa o OneHotEncoding\n",
        "data = pd.get_dummies(data, columns=cols_cat, drop_first=True)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d3963ab",
      "metadata": {
        "id": "4d3963ab"
      },
      "source": [
        "### Convertendo a Vari√°vel Alvo\n",
        "\n",
        "A nossa vari√°vel alvo, `inadimplente` √© a √∫nica vari√°vel que ainda precisa ser convertida. Para classifica√ß√£o bin√°ria (duas classes) vamos dividir as classes em Classe 0 (n√£o) e Classe 1 (sim).\n",
        "\n",
        "Ficando desta forma as entradas 0 para n√£o inadimplentes e 1 para clientes inadimplentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c906118",
      "metadata": {
        "id": "9c906118"
      },
      "outputs": [],
      "source": [
        "# Convertendo a vari√°vel alvo\n",
        "conversao_alvo = {\n",
        "    'inadimplente': {'nao': 0, 'sim': 1}\n",
        "}\n",
        "\n",
        "data.replace(conversao_alvo, inplace=True)\n",
        "data['inadimplente']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cd08caf",
      "metadata": {
        "id": "5cd08caf"
      },
      "source": [
        "## Lidando com Valores Faltantes\n",
        "\n",
        "**Existem diversas formas de tratar valores faltantes.** N√≥s podemos remover as entradas, substituir os valores faltantes com a M√©dia ou Mediana das colunas, ou muitas outras abordagens.\n",
        "\n",
        "Ao inv√©s de dropar/remover essas linhas com valores faltantes, iremos **substituir os valores faltantes** com a sua **M√©dia**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "715e129e",
      "metadata": {
        "id": "715e129e"
      },
      "outputs": [],
      "source": [
        "# Imputando os valores nulos com a m√©dia\n",
        "data = data.fillna(data.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ca3fa3c",
      "metadata": {
        "id": "7ca3fa3c"
      },
      "outputs": [],
      "source": [
        "# Verifica valores nulos novamente\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99c93aef",
      "metadata": {
        "id": "99c93aef"
      },
      "source": [
        "N√£o temos mais dados nulos/faltantes.\n",
        "\n",
        "<center><strong>Neste ponto, finalizamos a prepara√ß√£o dos dados</strong></center>\n",
        "\n",
        "<br>\n",
        "\n",
        "## Divis√£o dos Dados\n",
        "\n",
        "Iremos agora separar as caracter√≠sticas de cada paciente, as vari√°veis independentes, da nossa vari√°vel alvo, ou vari√°vel dependente.\n",
        "\n",
        "Lembre-se que chamamos de `X` o conjunto de caracter√≠sticas (*features*) e chamamos de `y` a nossa resposta de interesse, nossa vari√°vel alvo a ser descoberta (*target*).\n",
        "\n",
        "Ser√° necess√°rio tamb√©m adicionar uma constante de `1.0` √† matriz `X` de caracter√≠sticas para que o algoritmo possa realizar seus c√°lculos de forma precisa e eficiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abeead1c",
      "metadata": {
        "id": "abeead1c"
      },
      "outputs": [],
      "source": [
        "# Vari√°veis independentes (caracter√≠sticas)\n",
        "X = data.drop(['inadimplente'], axis=1)\n",
        "\n",
        "# Vari√°vel dependente (alvo)\n",
        "y = data['inadimplente']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4ecf3dd",
      "metadata": {
        "id": "e4ecf3dd"
      },
      "source": [
        "Precisamos agora dividir a nossa base de dados entre Treino e Teste. J√° discutimos a import√¢ncia desta divis√£o, onde separamos uma parte dos dados (70% neste caso) para realizarmos o treino do modelo e uma outra parte (30%) para testarmos e vermos se o modelo de fato aprendeu, ou se apenas \"decorou\" respostas e se \"ajustou demais\" ao problema (*Overfitting*).\n",
        "\n",
        "Como temos um certo desbalanceio na nossa vari√°vel alvo, √© interessante mantermos as mesmas propor√ß√µes de classes positivas e negativas tanto na base de treino quanto na de teste. A divis√£o √© aleat√≥ria, e n√£o devemos perder esta propor√ß√£o. \n",
        "\n",
        "Para isso, iremos fazer uso do argumento `stratify=y` da fun√ß√£o `train_test_split()` dispon√≠vel na biblioteca Scikit-learn. Este argumento ir√° manter as devidas propor√ß√µes das classes de `y` para treino e teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74dbec5e",
      "metadata": {
        "id": "74dbec5e"
      },
      "outputs": [],
      "source": [
        "# Divis√£o dos dados em Treino e Teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                   test_size=0.30,\n",
        "                                                   random_state=1,\n",
        "                                                   stratify=y) # mant√©m as propor√ß√µes das classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "875c1706",
      "metadata": {
        "id": "875c1706"
      },
      "source": [
        "Lembram que as classes estavam desbalanceadas? Isso √© de se esperar, pois muito provavelmente apenas uma parcela pequena de clientes de um banco devem ser inadimplentes.\n",
        "\n",
        "Nesse nosso caso, temos 70% de clientes n√£o inadimplentes (Classe 0) e 30% de clientes inadimplentes (Classe 1). Ao usarmos o argumento `stratify=y` na fun√ß√£o `train_test_split()`, n√≥s dizemos para a biblioteca manter essa propor√ß√£o quando fizer a divis√£o entre bases de treino e base de teste.\n",
        "\n",
        "Vamos verificar estas propor√ß√µes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf445e37",
      "metadata": {
        "id": "cf445e37"
      },
      "outputs": [],
      "source": [
        "# Verifica as propor√ß√µes de classes nos dados\n",
        "print('### Propor√ß√£o de Classes em Treino ###')\n",
        "print(f'Porcentagem de entradas Classe 0: {y_train.value_counts(normalize=True).values[0] * 100}%')\n",
        "print(f'Porcentagem de entradas Classe 1: {y_train.value_counts(normalize=True).values[1] * 100}%')\n",
        "print()\n",
        "\n",
        "print('### Propor√ß√£o de Classes em Teste ###')\n",
        "print(f'Porcentagem de entradas Classe 0: {y_test.value_counts(normalize=True).values[0] * 100}%')\n",
        "print(f'Porcentagem de entradas Classe 1: {y_test.value_counts(normalize=True).values[1] * 100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13570fa9",
      "metadata": {
        "id": "13570fa9"
      },
      "source": [
        "## Fun√ß√µes para Performance dos Modelos\n",
        "\n",
        "Iremos agora declarar algumas fun√ß√µes √∫teis para monitorarmos a performance dos nossos modelos.\n",
        "\n",
        "Se voc√™ precisa entender melhor como avaliamos modelos de classifica√ß√£o, recomendo fortemente a leitura do post [Medidas de Performance: Modelos de Classifica√ß√£o](https://brains.dev/2023/medidas-de-performance-modelos-de-classificacao/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e43aeca",
      "metadata": {
        "id": "6e43aeca"
      },
      "outputs": [],
      "source": [
        "def performance_modelo_classificacao(\n",
        "    model: object,\n",
        "    flag: Optional[bool] = True):\n",
        "    \n",
        "    '''\n",
        "    Fun√ß√£o para computar as diferentes m√©tricas de performance para modelos de classifica√ß√£o.\n",
        "\n",
        "    model: modelo para prever os valores de X\n",
        "    flag: se imprimimos ou n√£o os resultados\n",
        "    '''\n",
        "    \n",
        "    # Lista para armazenar os resultados de Treino e Valida√ß√£o\n",
        "    score_list = []\n",
        "    \n",
        "    # Predi√ß√£o em Treino e Valida√ß√£o\n",
        "    pred_train = model.predict(X_train)\n",
        "    pred_val = model.predict(X_test)\n",
        "    \n",
        "    # Acur√°cia do modelo\n",
        "    train_acc = model.score(X_train, y_train)\n",
        "    val_acc = model.score(X_test, y_test)\n",
        "    \n",
        "    # Recall do modelo \n",
        "    train_recall = recall_score(y_train, pred_train)\n",
        "    val_recall = recall_score(y_test, pred_val)\n",
        "    \n",
        "    # Precis√£o do modelo\n",
        "    train_prec = precision_score(y_train, pred_train)\n",
        "    val_prec = precision_score(y_test, pred_val)\n",
        "    \n",
        "    # F1-Score do modelo\n",
        "    train_f1 = f1_score(y_train, pred_train)\n",
        "    val_f1 = f1_score(y_test, pred_val)\n",
        "    \n",
        "    # Popula a lista\n",
        "    score_list.extend((train_acc, val_acc, train_recall, val_recall, train_prec, val_prec, train_f1, val_f1))\n",
        "    \n",
        "    # Imprime a lista se flag=True (default)\n",
        "    if flag:\n",
        "        print(f'Acur√°cia na base de Treino: {train_acc}')\n",
        "        print(f'Acur√°cia na base de Teste: {val_acc}')\n",
        "        print(f'\\nRecall na base de Treino: {train_recall}')\n",
        "        print(f'Recall na base de Teste: {val_recall}')\n",
        "        print(f'\\nPrecis√£o na base de Treino: {train_prec}')\n",
        "        print(f'Precis√£o na base de Teste: {val_prec}')\n",
        "        print(f'\\nF1-Score na base de Treino: {train_f1}')\n",
        "        print(f'F1-Score na base de Teste: {val_f1}')\n",
        "        \n",
        "    # Retorna a lista de valores em Treino e Valida√ß√£o\n",
        "    return score_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c70164a6",
      "metadata": {
        "id": "c70164a6"
      },
      "outputs": [],
      "source": [
        "def matriz_confusao(\n",
        "    model: object,\n",
        "    X: pd.DataFrame,\n",
        "    y_actual: pd.Series,\n",
        "    labels: Optional[tuple] = (1, 0)):\n",
        "    \n",
        "    '''\n",
        "    Plota a Matriz de Confus√£o com porcentagens.\n",
        "\n",
        "    model: modelo para prever os valores de X\n",
        "    X: atributos usados para a classfica√ß√£o\n",
        "    y_actual: classifica√ß√£o real, vari√°vel alvo\n",
        "    '''\n",
        "    \n",
        "    # Predi√ß√£o em Valida√ß√£o\n",
        "    y_predict = model.predict(X)\n",
        "    \n",
        "    # Pega os dados da Matriz de Confus√£o\n",
        "    cm = confusion_matrix(y_actual, y_predict, labels=[0, 1])\n",
        "    df_cm = pd.DataFrame(cm, index=['Real - N√£o (0)', 'Real - Sim (1)'],\n",
        "                        columns=['Previsto - N√£o (0)', 'Previsto - Sim (1)'])\n",
        "    \n",
        "    # List of labels for the Confusion Matrix\n",
        "    group_counts = [f'{value:.0f}' for value in cm.flatten()]\n",
        "    group_percentages = [f'{value:.2f}%' for value in (cm.flatten()/np.sum(cm))*100]\n",
        "    \n",
        "    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_counts, group_percentages)]\n",
        "    labels = np.asarray(labels).reshape(2, 2)\n",
        "    \n",
        "    # Plot the Confusion Matrix\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(df_cm, annot=labels, fmt='')\n",
        "    plt.xlabel('Classe Prevista', fontweight='bold')\n",
        "    plt.ylabel('Classe Verdadeira', fontweight='bold')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed0b3b17",
      "metadata": {
        "id": "ed0b3b17"
      },
      "outputs": [],
      "source": [
        "def importancias_variaveis(model: object):\n",
        "    '''\n",
        "    model: modelo para prever os valores de X\n",
        "    '''\n",
        "    \n",
        "    importances = model.feature_importances_\n",
        "    indices = np.argsort(importances)\n",
        "    feature_names = list(X.columns)\n",
        "    \n",
        "    plt.figure(figsize=(12,12))\n",
        "    plt.barh(y=range(len(indices)), width=importances[indices], color='violet', align='center')\n",
        "    plt.title('Import√¢ncia do Atributo', fontsize=16, fontweight='bold')\n",
        "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "    plt.xlabel('Import√¢ncia Relativa', fontweight='bold')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f327539",
      "metadata": {
        "id": "8f327539"
      },
      "source": [
        "## Treino dos Modelos de √Årvores de Decis√£o\n",
        "\n",
        "O treino do nosso primeiro modelo vai ser extremamente simples. Depois iremos adicionar um pouco de complexidade.\n",
        "\n",
        "N√≥s iremos usar a classe [sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) para construir de forma automatizada a nossa melhor √Årvore de Decis√£o.\n",
        "\n",
        "Para isso iremos instanciar um objeto `DecisionTreeClassifier()` e fazermos com que ele se ajuste aos nossos dados de treino, que √© o nosso processo de treino, com o m√©todo `.fit()`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86b09c19",
      "metadata": {
        "id": "86b09c19"
      },
      "source": [
        "### Criando e Treinando o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd75519",
      "metadata": {
        "id": "bcd75519"
      },
      "outputs": [],
      "source": [
        "# Instanciando o Modelo\n",
        "arvore_d = DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "# Treinando o modelo\n",
        "arvore_d.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da3f18b5",
      "metadata": {
        "id": "da3f18b5"
      },
      "source": [
        "### M√©tricas da √Årvore de Decis√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e736919c",
      "metadata": {
        "id": "e736919c"
      },
      "outputs": [],
      "source": [
        "arvore_d_scores = performance_modelo_classificacao(arvore_d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2896ce63",
      "metadata": {
        "id": "2896ce63"
      },
      "source": [
        "Perceberam um **forte** Overfitting? A √Årvore de Decis√£o cresceu sem controle e acertou 100% de todas as observa√ß√µes de treino, mas falhou na base de teste. Aparentemente o modelo est√° decorando as respostas da base de treino e sua performance real est√° similar a jogar cara ou coroa.\n",
        "\n",
        "Vamos tentar visualizar isso na Matriz de Confus√£o.\n",
        "\n",
        "### Matriz de Confus√£o para a √Årvore de Decis√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8068f9bc",
      "metadata": {
        "id": "8068f9bc"
      },
      "outputs": [],
      "source": [
        "# Matriz de Confus√£o de treino\n",
        "matriz_confusao(arvore_d, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "102a270e",
      "metadata": {
        "id": "102a270e"
      },
      "outputs": [],
      "source": [
        "# Matriz de Confus√£o de teste\n",
        "matriz_confusao(arvore_d, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ddc5892",
      "metadata": {
        "id": "5ddc5892"
      },
      "source": [
        "Perceberam que na primeira matriz tivemos 0 erros e na segunda muitos erros?\n",
        "\n",
        "Vamos agora visualizar quais decis√µes essa √°rvore est√° tomando, e em que ordem.\n",
        "\n",
        "### Visualizando a √Årvore de Decis√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1065ac",
      "metadata": {
        "id": "af1065ac"
      },
      "outputs": [],
      "source": [
        "feature_names = list(X_train.columns)\n",
        "\n",
        "plt.figure(figsize=(20, 30))\n",
        "tree.plot_tree(arvore_d, feature_names=feature_names, filled=True,\n",
        "            fontsize=9, node_ids=True, class_names=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd51d7a",
      "metadata": {
        "id": "4cd51d7a"
      },
      "source": [
        "√â uma √°rvore extremamente complexa e profunda! Um modelo complexo demais tende ao Overfitting. Para evitar que nossas √Årvores de Decis√£o crescam sem controle, n√≥s vamos fazer uso de uma t√©cnica de **Poda**. Vamos fazer a **Pr√©-Poda**, para sermos mais exatos.\n",
        "\n",
        "## √Årvore de Decis√£o com Pr√©-Poda\n",
        "\n",
        "Vamos, primeiramente, controlar a profundidade desta √Årvore de Decis√£o a deixando mais simples. Para isso, vamos usar o par√¢metro `max_depth` quando instanciarmos o objeto do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cb4a2a1",
      "metadata": {
        "id": "5cb4a2a1"
      },
      "source": [
        "### Criando e Treinando a √Årvore de Decis√£o Podada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b2f875f",
      "metadata": {
        "id": "5b2f875f"
      },
      "outputs": [],
      "source": [
        "# Instanciando o Modelo\n",
        "arvore_d1 = DecisionTreeClassifier(random_state=1, max_depth=3)\n",
        "\n",
        "# Treinando o modelo\n",
        "arvore_d1.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6718ba8",
      "metadata": {
        "id": "a6718ba8"
      },
      "source": [
        "### M√©tricas da √Årvore de Decis√£o Podada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6818517",
      "metadata": {
        "id": "a6818517"
      },
      "outputs": [],
      "source": [
        "arvore_d1_scores = performance_modelo_classificacao(arvore_d1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9058162",
      "metadata": {
        "id": "b9058162"
      },
      "source": [
        "Agora parece que n√≥s temos um **Underfitting**, concordam? Talvez o modelo esteja simples demais para aprender algo suficiente da base de treino.\n",
        "\n",
        "Vamos analisar novamente a Matriz de Confus√£o."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1959534b",
      "metadata": {
        "id": "1959534b"
      },
      "outputs": [],
      "source": [
        "# Matriz de Confus√£o de treino\n",
        "matriz_confusao(arvore_d1, X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b53a2923",
      "metadata": {
        "id": "b53a2923"
      },
      "source": [
        "### Visualizando a √Årvore de Decis√£o Podada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec77cf16",
      "metadata": {
        "id": "ec77cf16"
      },
      "outputs": [],
      "source": [
        "feature_names = list(X_train.columns)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "tree.plot_tree(arvore_d1, feature_names=feature_names, filled=True,\n",
        "            fontsize=9, node_ids=True, class_names=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c34e4e7",
      "metadata": {
        "id": "8c34e4e7"
      },
      "source": [
        "De fato a nossa √Årvore de Decis√£o est√° bem simples. Aparentemente simples **demais** para nossos dados, causando assim um **Underfitting**.\n",
        "\n",
        "Ajustar a profundidade m√°xima da √°rvore para tr√™s n√≠veis n√£o foi uma boa estrat√©gia. Voc√™s devem se lembrar que temos outros par√¢metros que podemos trabalhar para controlar o crescimento da √°rvore, certo? Se voc√™ n√£o lembra, leia o post [√Årvores de Decis√£o: Algoritmos Baseados em √Årvores](https://brains.dev/2023/arvores-de-decisao-algoritmos-baseados-em-arvores/).\n",
        "\n",
        "Mas como encontrar os valores ideais de par√¢metros?\n",
        "\n",
        "## Ajuste de Hiperpar√¢metros\n",
        "\n",
        "O **Ajuste de Hiperpar√¢matros** (do Ingl√™s, *Hyperparameter Tuning*) √© o processo de realizar altera√ß√µes nos par√¢metros de um modelo com o intu√≠to de melhorar a sua performance.\n",
        "\n",
        "Para isso podemos usar a classe [`GridSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), que far√° uma s√©rie de tentativas combinando diferentes par√¢metros definidos dentro de uma grade e implementando a Valida√ß√£o Cruzada (*Cross Validation*) para chegar at√© a melhor combina√ß√£o.\n",
        "\n",
        "### Criando e Treinando a √Årvore de Decis√£o Tunada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c5f92d",
      "metadata": {
        "id": "06c5f92d"
      },
      "outputs": [],
      "source": [
        "# Escolhe o Algoritmo\n",
        "algo = DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "# Grade de par√¢metros para combinar\n",
        "parameters = {'max_depth': np.arange(1, 10),\n",
        "             'min_samples_leaf': [1, 2, 5, 7, 10, 15, 20],\n",
        "             'max_leaf_nodes': [2, 3, 5, 10],\n",
        "             'min_impurity_decrease': [0.001, 0.01, 0.1]\n",
        "             }\n",
        "\n",
        "# M√©trica usada para comparar as combina√ß√µes de par√¢metros\n",
        "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
        "\n",
        "# Roda a Grid Search\n",
        "grid_obj = GridSearchCV(algo, parameters, scoring=acc_scorer, cv=5)\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Cria o modelo com a melhor combina√ß√£o\n",
        "arvore_d2 = grid_obj.best_estimator_\n",
        "\n",
        "# Treina o modelo\n",
        "arvore_d2.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16f06877",
      "metadata": {
        "id": "16f06877"
      },
      "source": [
        "### M√©tricas da √Årvore de Decis√£o Tunada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf074de",
      "metadata": {
        "id": "5bf074de"
      },
      "outputs": [],
      "source": [
        "arvore_d2_scores = performance_modelo_classificacao(arvore_d2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5378d74f",
      "metadata": {
        "id": "5378d74f"
      },
      "source": [
        "Voc√™ deve ter notado que todas essas tentativas de diferentes combina√ß√µes de par√¢metros demora um pouco para executar. Mas vejam s√≥! Nossa profundidade ideal √© de 7 n√≠veis, com 10 n√≥s folhas. O algoritmo escolheu essa melhor combina√ß√£o dentro do espa√ßo amostral que oferecemos pra ele.\n",
        "\n",
        "Genial, n√©? E nosso modelo teve uma certa melhora. Vamos ver a Matriz de Confus√£o?\n",
        "\n",
        "### Matriz de Confus√£o para a √Årvore de Decis√£o Tunada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3596987",
      "metadata": {
        "id": "b3596987"
      },
      "outputs": [],
      "source": [
        "# Matriz de Confus√£o de treino\n",
        "matriz_confusao(arvore_d2, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "593a8542",
      "metadata": {
        "id": "593a8542"
      },
      "outputs": [],
      "source": [
        "# Matriz de Confus√£o de teste\n",
        "matriz_confusao(arvore_d2, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b639257c",
      "metadata": {
        "id": "b639257c"
      },
      "source": [
        "----------------\n",
        "\n",
        "# Comparando os Modelos\n",
        "\n",
        "Agora vamos listar todos os modelos para compararmos as m√©tricas de performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "822be8f3",
      "metadata": {
        "id": "822be8f3"
      },
      "outputs": [],
      "source": [
        "# Lista com todos os modelos\n",
        "modelos = ['√Årvore de Decis√£o',\n",
        "          '√Årvore de Decis√£o Podada', \n",
        "          '√Årvore de Decis√£o Tunada']\n",
        "\n",
        "# Nomes das colunas\n",
        "colunas = ['Treino_Acurarcia', 'Val_Acurarcia', 'Treino_Recall', 'Val_Recall',\n",
        "          'Treino_Precisao', 'Val_Precisao', 'Treino_F1', 'Val_F1']\n",
        "\n",
        "# DataFrame com todos os modelos e seus respectivos scores\n",
        "modelos_scores = pd.DataFrame([arvore_d_scores, arvore_d1_scores, arvore_d2_scores], \n",
        "                             columns=colunas, index=modelos).apply(lambda x: round(x, 2))\n",
        "\n",
        "modelos_scores.T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dfdb9dc",
      "metadata": {
        "id": "8dfdb9dc"
      },
      "source": [
        "# Conclus√µes\n",
        "\n",
        "- Todos os nossos modelos est√£o ou apresentando Overfitting ou apresentando Underfitting at√© o momento.\n",
        "\n",
        "- N√£o conseguimos encontrar ainda um algoritmo que apresente uma performance aceit√°vel para o nosso objetivo com este projeto.\n",
        "\n",
        "- Provavelmente precisaremos usar um algoritmo mais avan√ßado para este problema. Possivelmente as [Random Forests](https://brains.dev/2023/random-forests-algoritmos-baseados-em-arvores/) sejam uma boa escolha!\n",
        "\n",
        "<br>\n",
        "\n",
        "Caso tenha ficado com alguma d√∫vida, entre em contato conosco pelo site do [brains.dev](https://brains.dev). \n",
        "\n",
        "Colabore com a nossa comunidade trazendo conte√∫do de qualidade em Portugu√™s, seja conte√∫do pr√≥prio ou traduzido. Iremos ficar muito felizes de receber material de voc√™s.\n",
        "\n",
        "Para conhecer mais sobre n√≥s e saber como colaborar, visite o post abaixo.\n",
        "\n",
        "- [**Bem-vindos ao BRAINS**](https://brains.dev/2022/bem-vindos-ao-brains/)\n",
        "\n",
        "√â sempre um prazer estar com voc√™s por aqui!\n",
        "\n",
        "<br>\n",
        "\n",
        "<center><h2>#NoBrains #NoGains üß†</h2></center>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}